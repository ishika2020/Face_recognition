{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset and Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the id of user: 2\n",
      "Enter the name of user: Ishika\n"
     ]
    }
   ],
   "source": [
    "ID = input(\"Enter the id of user: \")\n",
    "Name = input(\"Enter the name of user: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aashi', 'Ishika']\n"
     ]
    }
   ],
   "source": [
    "Names.append(Name)\n",
    "print(Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import smtplib\n",
    "import pywhatkit as kt\n",
    "import boto3\n",
    "import getpass as gp\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-13-c9c8d796ffaf>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "# Load functions\n",
    "import cv2\n",
    "import numpy as np\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "# Collect samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = \"./dataset/\" + Name + \".\" + ID +\".\"+ str(count) + \".jpg\"\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Cropped img', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def Image_and_id(path):\n",
    "    image_paths = [os.path.join(path,f) for f in os.listdir(path)]\n",
    "    facesamples, Ids = [], []\n",
    "    \n",
    "    for imagepath in image_paths:\n",
    "        image = cv2.imread(imagepath, cv2.IMREAD_GRAYSCALE)\n",
    "        imagenp = np.asarray(image,dtype=np.uint8)\n",
    "        Id = int(os.path.split(imagepath)[-1].split(\".\")[1])\n",
    "        face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        faces = face_classifier.detectMultiScale(imagenp, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            facesamples.append(imagenp[y:y+h, x:x+w])\n",
    "            Ids.append(Id)\n",
    "    return facesamples , Ids\n",
    "\n",
    "\n",
    "\n",
    "model  = cv2.face.LBPHFaceRecognizer_create()\n",
    "faces , Id = Image_and_id(\"./dataset/\")\n",
    "#Let's train our model \n",
    "model.train(faces, np.array(Id))\n",
    "print(\"Model trained sucessefully\")\n",
    "model.save(\"./Trained_model.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_sender(sender,password,receiver,msg):\n",
    "    s=smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    s.starttls()\n",
    "    s.login(sender,password)\n",
    "    s.sendmail(sender,receiver, msg)\n",
    "    s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def whatapp_sender(phonenumber,msg):\n",
    "    obj_now = datetime.datetime.now()\n",
    "    kt.sendwhatmsg_instantly(phonenumber,msg,wait_time=15)\n",
    " #   kt.sendwhatmsg(phonenumber,msg,time_hour=obj_now.hour,time_min=obj_now.minute+1,wait_time=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def launchec2Instance():\n",
    "    client = boto3.client(\"ec2\", region_name=\"ap-south-1\")\n",
    "    instances = client.run_instances(\n",
    "        ImageId=\"ami-06a0b4e3b7eb7a300\",\n",
    "        MinCount=1,\n",
    "        MaxCount=1,\n",
    "        InstanceType=\"t2.micro\",\n",
    "        KeyName=\"awsinstancekey\"\n",
    "    )\n",
    "    print(\"Instance launched\",instances[\"Instances\"][0][\"InstanceId\"])\n",
    "    \n",
    "    #for volume\n",
    "    volume = client.create_volume(\n",
    "        AvailabilityZone='ap-south-1a',\n",
    "        Size=5,\n",
    "        VolumeType= 'gp2'\n",
    "    )\n",
    "    volumeid=volume[\"VolumeId\"]\n",
    "    print(\"volume Created\",volume[\"VolumeId\"])\n",
    "\n",
    "def  attach_volume():\n",
    "    time.sleep(10)\n",
    "    client = boto3.client(\"ec2\", region_name=\"ap-south-1\")\n",
    "    response = client.attach_volume(\n",
    "        Device='sdb',\n",
    "        InstanceId=instances[\"Instances\"][0][\"InstanceId\"],\n",
    "        VolumeId=volume[\"VolumeId\"],\n",
    "    )\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face recognition by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-24-4be7664b3575>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "launched 89\n",
      "Instance launched i-0615de71174d1dd3f\n",
      "volume Created vol-0a9a05bf3b6d4299a\n"
     ]
    }
   ],
   "source": [
    "#face recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "launched = False\n",
    "sent = False\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    image, face = face_detector(frame)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        results = model.predict(face)\n",
    "        id = results[0]\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            conf = int(100*(1- results[1]/400))\n",
    "            st = str(conf) + '% confidence of ' + Names[id-1]\n",
    "            cv2.putText(image, st, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "            cv2.imshow('Face_Recognition', image ) \n",
    "            \n",
    "        if conf > 88 and id == 1 and launched == False:\n",
    "            cv2.imshow('Face_Recognition', image )  \n",
    "            print(\"launched\",conf)\n",
    "            launchec2Instance()\n",
    "            #break\n",
    "            launched = True\n",
    "            \n",
    "            \n",
    "        elif conf > 88 and id == 2 and sent == False:\n",
    "            cv2.imshow('Face_Recognition', image )  \n",
    "            email_sender(\"facerecognition963@gmail.com\",\"[123abc]\",\"shivanimandloi122324@gmail.com\", Names[id-1]+\" detected \")\n",
    "            whatapp_sender(\"+919021837700\", str(Names[id-1]) +\" detected \")\n",
    "            #break\n",
    "            sent = True\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "            \n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (50, 50) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face_Recognition', image )\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break    \n",
    "                    \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
